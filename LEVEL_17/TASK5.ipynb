{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ccca56b-bf6a-46fb-ba53-69f6dc2f06de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n|year|no_of_teams|\n+----+-----------+\n+----+-----------+\n\n+------+-----+\n|status|count|\n+------+-----+\n+------+-----+\n\n+------+---------+\n|inning|avg_balls|\n+------+---------+\n|     1|      2.5|\n|     2|      1.0|\n+------+---------+\n\n+----+------------+-----+\n|year|match_winner|count|\n+----+------------+-----+\n+----+------------+-----+\n\n+--------+------+------------------------------+--------------------+\n|match_id|team  |batsmen_list                  |batsmen_set         |\n+--------+------+------------------------------+--------------------+\n|1       |Team A|[Player 1, Player 2, Player 1]|[Player 2, Player 1]|\n|1       |Team B|[Player 3, Player 4]          |[Player 4, Player 3]|\n+--------+------+------------------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, year, countDistinct, count, avg, collect_list, collect_set, when\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = spark.read.parquet(\"dbfs:/FileStore/ipl_validated.parquet/\")\n",
    "\n",
    "# 1\n",
    "teams_each_year = df.select(\"year\", \"match_team1\").withColumnRenamed(\"match_team1\", \"team\") \\\n",
    "    .union(df.select(\"year\", col(\"match_team2\").alias(\"team\"))) \\\n",
    "    .distinct().groupBy(\"year\").agg(countDistinct(\"team\").alias(\"no_of_teams\"))\n",
    "teams_each_year.show()\n",
    "\n",
    "# 2\n",
    "status_df = df.withColumn(\"status\", \n",
    "    when(col(\"match_venue\").isNull(), \"Abandoned\")\n",
    "    .when(col(\"match_name\").like(\"%Tied%\"), \"Tied\")\n",
    "    .otherwise(\"Completed\"))\n",
    "status_counts = status_df.groupBy(\"status\").count()\n",
    "status_counts.show()\n",
    "\n",
    "# 3\n",
    "from pyspark.sql import Row\n",
    "\n",
    "sample_ball_data = [\n",
    "    Row(match_id=1, inning=1, ball_no=1),\n",
    "    Row(match_id=1, inning=1, ball_no=2),\n",
    "    Row(match_id=1, inning=2, ball_no=1),\n",
    "    Row(match_id=2, inning=1, ball_no=1),\n",
    "    Row(match_id=2, inning=1, ball_no=2),\n",
    "    Row(match_id=2, inning=1, ball_no=3),\n",
    "]\n",
    "ball_df = spark.createDataFrame(sample_ball_data)\n",
    "\n",
    "avg_ball_per_inning = ball_df.groupBy(\"match_id\", \"inning\").agg(count(\"ball_no\").alias(\"balls\")) \\\n",
    "    .groupBy(\"inning\").agg(avg(\"balls\").alias(\"avg_balls\"))\n",
    "avg_ball_per_inning.show()\n",
    "\n",
    "#4\n",
    "df_winners = df.withColumn(\"match_winner\", col(\"match_team1\")\n",
    "matches_won = df_winners.groupBy(\"year\", \"match_winner\").count().orderBy(\"year\", \"count\", ascending=[True, False])\n",
    "matches_won.show()\n",
    "\n",
    "# 5\n",
    "sample_commentary = [\n",
    "    Row(match_id=1, team=\"Team A\", batsman=\"Player 1\"),\n",
    "    Row(match_id=1, team=\"Team A\", batsman=\"Player 2\"),\n",
    "    Row(match_id=1, team=\"Team A\", batsman=\"Player 1\"),  # duplicate\n",
    "    Row(match_id=1, team=\"Team B\", batsman=\"Player 3\"),\n",
    "    Row(match_id=1, team=\"Team B\", batsman=\"Player 4\")\n",
    "]\n",
    "commentary_df = spark.createDataFrame(sample_commentary)\n",
    "\n",
    "batsmen_list = commentary_df.groupBy(\"match_id\", \"team\") \\\n",
    "    .agg(\n",
    "        collect_list(\"batsman\").alias(\"batsmen_list\"),\n",
    "        collect_set(\"batsman\").alias(\"batsmen_set\")\n",
    "    )\n",
    "batsmen_list.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "43190361-1179-4a35-8556-312e720458dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LEVEL17 T5",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}